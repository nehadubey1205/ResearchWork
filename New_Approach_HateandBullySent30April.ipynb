{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOEfMk02L/XMVt76AStrPFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehadubey1205/ResearchWork/blob/main/New_Approach_HateandBullySent30April.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6aJ0BudxwLC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/combined_file_New.csv')"
      ],
      "metadata": {
        "id": "RURZzZmCxy7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(2)"
      ],
      "metadata": {
        "id": "mq0jbahpxy4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGTToF5-zfQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first three rows of the DataFrame\n",
        "data.iloc[5900:6200]"
      ],
      "metadata": {
        "id": "L4HoP3-Hxy2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to remove 6084\n",
        "data= data.drop(index=[6084])"
      ],
      "metadata": {
        "id": "egroK9F_xyzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "7d4LqeRFxywr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "SZAOZubnxyuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "6brU2PN11PAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ],
      "metadata": {
        "id": "0Bj216VH1rd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install transformers"
      ],
      "metadata": {
        "id": "TIy9ZLyE14tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "St42o3fi1wrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "     \n",
        "\n",
        "\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "coWirGc-1nxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Processed_Tweets'].values\n",
        "y = data['Bully_Label'].values\n",
        "     \n",
        "\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "OaZAioDhxyr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "     \n",
        "\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X = pad_sequences(X, maxlen=100)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Creating the deep learning model\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 128, input_length=X.shape[1]))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "metadata": {
        "id": "LE-IWGZMxypi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.callbacks import EarlyStopping\n",
        "#from keras.utils import to_categorical\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, to_categorical(y_train), epochs=10, batch_size=64, validation_split=0.2,\n",
        "          callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.01)])"
      ],
      "metadata": {
        "id": "K_KJAp3CxymJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = np.argmax(model.predict(X_test), axis=-1)"
      ],
      "metadata": {
        "id": "8IPc_YnS3wjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the performance of the model\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_predict)"
      ],
      "metadata": {
        "id": "U2eW9cH230OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "precision = precision_score(y_test, y_predict, average='weighted')\n",
        "recall = recall_score(y_test, y_predict, average='weighted')\n",
        "f1 = f1_score(y_test, y_predict, average='weighted')\n",
        "     \n",
        "\n",
        "#print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "e1HJzhevxykj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEATrfxX42DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM -2 **LSTM second Methode**"
      ],
      "metadata": {
        "id": "__q0ifBR40RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "NtRQwPGw9fPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/combined_file_New.csv\")"
      ],
      "metadata": {
        "id": "kNsyR3__9kKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "aWKfLtXx9pB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(index=[6084])"
      ],
      "metadata": {
        "id": "0gVJuUnf90Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unwanted columns and clean the text\n",
        "df = df[['Processed_Tweets', 'Bully_Label']]\n",
        "df['Processed_Tweets'] = df['Processed_Tweets'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "df['Processed_Tweets'] = df['Processed_Tweets'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
        "df['Processed_Tweets'] = df['Processed_Tweets'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "0oJi9FHF-Esl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "id": "bDFLmqo6-rN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "train_df['Processed_Tweets'] = train_df['Processed_Tweets'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "test_df['Processed_Tweets'] = test_df['Processed_Tweets'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
      ],
      "metadata": {
        "id": "wSlbJDVS-X8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to numerical values\n",
        "train_df['Bully_Label'] = train_df['Bully_Label'].astype('category').cat.codes\n",
        "test_df['Bully_Label'] = test_df['Bully_Label'].astype('category').cat.codes\n"
      ],
      "metadata": {
        "id": "YYWoUOr-xygs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train = vectorizer.fit_transform(train_df['Processed_Tweets'])\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test = vectorizer.transform(test_df['Processed_Tweets'])"
      ],
      "metadata": {
        "id": "2DQGDEoG_FPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to numpy arrays\n",
        "y_train = np.array(train_df['Bully_Label'])\n",
        "y_test = np.array(test_df['Bully_Label'])"
      ],
      "metadata": {
        "id": "FDD3ttxc_NFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the text data to sequences of integers\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(train_df['Processed_Tweets'])\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['Processed_Tweets'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['Processed_Tweets'])\n",
        "\n",
        "# Pad the sequences to a fixed length\n",
        "X_train_seq = pad_sequences(X_train_seq, maxlen=500)\n",
        "X_test_seq = pad_sequences(X_test_seq, maxlen=500)\n"
      ],
      "metadata": {
        "id": "9KjvMmFKxyX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=64, input_length=500))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "KCow51MG_lO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hIKyqeXz_pVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "model.fit(X_train_seq, y_train, batch_size=32, epochs=10, validation_data=(X_test_seq, y_test))\n"
      ],
      "metadata": {
        "id": "i7ABaEBtxyVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_seq, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "qn8_o7FzxyTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test_seq)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Print the precision, recall, and F1 score\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "WnRKi_ylxyQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voting Classifiers"
      ],
      "metadata": {
        "id": "e_HPNapHGpRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-QSKb0VHOhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/combined_file_New.csv')"
      ],
      "metadata": {
        "id": "eVkhQPJxGo0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to remove 6084\n",
        "df= df.drop(index=[6084])"
      ],
      "metadata": {
        "id": "jsQHGkHBHPLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(2)"
      ],
      "metadata": {
        "id": "O9c2-4oUHbGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "2gKCpzeBHpCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "metadata": {
        "id": "xEqcU3KHHsT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download Hinglish stop words\n",
        "nltk.download('stopwords-indian')\n",
        "     \n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "8kmPZRcbH51V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the dataset\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "     \n",
        "\n",
        "X = vectorizer.fit_transform(df['Processed_Tweets'])\n",
        "y = df['Bully_Label']"
      ],
      "metadata": {
        "id": "Nep2oTYqH90o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating base models\n",
        "model1 = DecisionTreeClassifier()\n",
        "model2 = SVC(kernel='linear', probability=True)\n",
        "model3 = MultinomialNB()"
      ],
      "metadata": {
        "id": "eG2_s_bMIBdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an ensemble model\n",
        "ensemble = VotingClassifier(estimators=[('dt', model1), ('svm', model2), ('nb', model3)], voting='soft')\n",
        "\n",
        "# Training the ensemble model\n",
        "ensemble.fit(X, y)"
      ],
      "metadata": {
        "id": "QyeAlOZvIEup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the performance of the model\n",
        "y_pred = ensemble.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "precision = precision_score(y, y_pred, average='weighted')\n",
        "recall = recall_score(y, y_pred, average='weighted')\n",
        "f1 = f1_score(y, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "XkH3MFbZxyOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT Model"
      ],
      "metadata": {
        "id": "CnSeVVi0JcT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "BtAZH_7MKw9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "QcBjO5LNK2Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ],
      "metadata": {
        "id": "4FOFkAFcKi56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from the CSV file\n",
        "df = pd.read_csv('/content/combined_file_New.csv')\n",
        "# we want to remove 6084\n",
        "df= df.drop(index=[6084])\n"
      ],
      "metadata": {
        "id": "o24FMUYEKmgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomize the rows\n",
        "#df= df.sample(frac=1)"
      ],
      "metadata": {
        "id": "gPkvG0KHKsmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(10)"
      ],
      "metadata": {
        "id": "F46KonbpK_Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Load the BERT model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
        "\n",
        "# Tokenize the text messages\n",
        "train_encodings = tokenizer(list(train_df['Processed_Tweets']), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_df['Processed_Tweets']), truncation=True, padding=True)\n",
        "\n",
        "# Convert the labels to numerical values\n",
        "train_labels = np.array(list(train_df['Bully_Label'])).astype(int)\n",
        "test_labels = np.array(list(test_df['Bully_Label'])).astype(int)\n",
        "\n",
        "# Create a PyTorch dataset from the encoded data\n",
        "class CyberbullyingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Define a function to compute metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "0Zh3vfdfMwsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a Trainer object\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='epoch'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=CyberbullyingDataset(train_encodings, train_labels),\n",
        "    eval_dataset=CyberbullyingDataset(test_encodings, test_labels),\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "1rm4DwjWMshN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "eval_result = trainer.evaluate()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {eval_result['eval_accuracy']}\")\n",
        "print(f\"F1 Score: {eval_result['eval_f1']}\")\n",
        "print(f\"Precision: {eval_result['eval_precision']}\")\n",
        "print(f\"Recall: {eval_result['eval_recall']}\")"
      ],
      "metadata": {
        "id": "L2PAOZwdMse0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DuOSGKrRMscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDhGOszgMsZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JyiaFfYMsXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1F6z14sMsUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SEyBekIIMsPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqJfceB9xyBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsdsUkYVxx-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_0b1whtxx88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oI9uSsJbxx6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALPV2VqIxx3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}